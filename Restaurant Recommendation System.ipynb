{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Restaurent Recommendation"],"metadata":{"id":"c8Fnew5j3p9i"}},{"cell_type":"markdown","source":["###Context"],"metadata":{"id":"sb5UjjP83rAZ"}},{"cell_type":"markdown","source":[],"metadata":{"id":"I9eRs3hpaeJS"}},{"cell_type":"markdown","source":["### Objective"],"metadata":{"id":"9LsZmvr5347W"}},{"cell_type":"markdown","source":[],"metadata":{"id":"IHJ9jQ8KcJkZ"}},{"cell_type":"markdown","source":["### Data Description\n","\n","- 0   Age   -                                     388 non-null  |  int64  \n","- 1   Gender -                                    388 non-null  |  object\n","- 2   Marital Status -                             388 non-null |   object\n","- 3   Occupation      -                           388 non-null   |  object\n","- 4   Monthly Income                             388 non-null   | object  \n","- 5   Educational Qualifications  -               388 non-null  |  object\n","- 6   Family size      -                          388 non-null   | int64  \n","- 7   latitude   -                                388 non-null   | float64\n","- 8   longitude   -                               388 non-null   | float64\n","- 9   Pin code    -                               388 non-null  | int64  \n","- 10  Medium (P1)   -                             388 non-null  |  object\n","- 11  Medium (P2)   -                             388 non-null   | object\n","- 12  Meal(P1)      -                             388 non-null   | object\n","- 13  Meal(P2)       -                            388 non-null   | object\n","- 14  Perference(P1)   -                          388 non-null  |  object\n","- 15  Perference(P2)   -                          388 non-null   | object\n","- 16  Ease and convenient -                       388 non-null  |  object\n","- 17  Time saving        -                        388 non-null   | object\n","- 18  More restaurant choices -                   388 non-null   | object\n","- 19  Easy Payment option     -                   388 non-null   | object\n","- 20  More Offers and Discount  -                 388 non-null  |  object\n","- 21  Good Food quality       -                   388 non-null   | object\n","- 22  Good Tracking system       -                388 non-null  |  object\n","- 23  Self Cooking        -                       388 non-null  |  object\n","- 24  Health Concern    -                        388 non-null   | object\n","- 25  Late Delivery        -                      388 non-null  |  object\n","- 26  Poor Hygiene         -                      388 non-null   | object\n","- 27  Bad past experience   -                     388 non-null   | object\n","- 28  Unavailability        -                     388 non-null  |  object\n","- 29  Unaffordable          -                    388 non-null   | object\n","- 30  Long delivery time    -                     388 non-null   | object\n","- 31  Delay of delivery person getting assigned - 388 non-null  |  object\n","- 32  Delay of delivery person picking up food -   388 non-null  |  object\n","- 33  Wrong order delivered        -              388 non-null  |  object\n","- 34  Missing item             -                  388 non-null  |  object\n","- 35  Order placed by mistake      -              388 non-null   | object\n","- 36  Influence of time        -                  388 non-null  |  object\n","- 37  Order Time                  -               388 non-null   | object\n","- 38  Maximum wait time            -              388 non-null   | object\n","- 39  Residence in busy location     -            388 non-null   | object\n","- 40  Google Maps Accuracy       -                388 non-null   | object\n","- 41  Good Road Condition         -               388 non-null   | object\n","- 42  Low quantity low time        -              388 non-null   | object\n","- 43  Delivery person ability       -             388 non-null   | object\n","- 44  Influence of rating          -              388 non-null   | object\n","- 45  Less Delivery time          -               388 non-null   | object\n","- 46  High Quality of package     -               388 non-null   | object\n","- 47  Number of calls           -                 388 non-null   | object\n","- 48  Politeness              -                   388 non-null   | object\n","- 49  Freshness                -                  388 non-null   | object\n","- 50  Temperature               -                 388 non-null   | object\n","- 51  Good Taste             -                    388 non-null   | object\n","- 52  Good Quantity          -                    388 non-null   | object\n","- 53  Output                 -                    388 non-null   | object\n","- 54  Reviews               -                     387 non-null   | object\n","- 55  Allergies              -                    346 non-null   | object\n","- 56  Food not allowed       -                    388 non-null   | object\n","\n","data.shape = (388,57)"],"metadata":{"id":"GlK-UCYQZt7Q"}},{"cell_type":"markdown","source":["# Understanding Data set"],"metadata":{"id":"t_b8J1Yh1NVR"}},{"cell_type":"markdown","source":["###Data Description"],"metadata":{"id":"n2a9bEoi4DtG"}},{"cell_type":"code","source":["from google.colab ___________ # (Finish the the block to import your data set from google colab if needed)\n","________________ ('/____/')"],"metadata":{"id":"xwSa-tdL4SEX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Importing necessary libraries and data"],"metadata":{"id":"rhC3Manb4wKM"}},{"cell_type":"code","source":["\n","# Libraries to help with reading and manipulating data\n","import _____ as np\n","import _____ as pd\n","\n","# Libraries to help with data visualization\n","import __________ as plt\n","import _______ as sns\n","\n","sns.set()\n","\n","# split the data into train and test\n","from _____________ import train_test_split\n","\n","# to build linear regression_model\n","from sklearn.linear_model import LinearRegression\n","\n","# to check model performance\n","from ____________ import mean_absolute_error, mean_squared_error, r2_score\n","\n","# to build linear regression_model using statsmodels\n","import statsmodels.api as sm\n","\n","# to compute VIF\n","from statsmodels.stats.outliers_influence import variance_inflation_factor"],"metadata":{"id":"GVYmdEp744cf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","data = pd._____csv('') ## Complete the code to read the data"],"metadata":{"id":"KDVeeSxs44fw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Overview"],"metadata":{"id":"aVY042He5a7f"}},{"cell_type":"code","source":["data.head()"],"metadata":{"id":"ETs2_XR15gJY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.info()"],"metadata":{"id":"KCj1Cd2b5gNI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.shape"],"metadata":{"id":"-2fnEO2a5gQh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.describe().T"],"metadata":{"id":"RkXdc5PR5gaQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(data.isnull().sum() / len(data)) * 100 # Check for missing values"],"metadata":{"id":"OxaPX-mR5neV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check for missing values\n","missing_values = data.isnull().sum()"],"metadata":{"id":"YM9R1cx55nlE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## EDA"],"metadata":{"id":"wxGrQqCUrCJ7"}},{"cell_type":"code","source":["# function to plot a boxplot and a histogram along the same scale.\n","\n","\n","def histogram_boxplot(data, feature, figsize=(__, ___), kde=False, bins=None):\n","    \"\"\"\n","    Boxplot and histogram combined\n","\n","    data: dataframe\n","    feature: dataframe column\n","    figsize: size of figure (default (15,10))\n","    kde: whether to show the density curve (default False)\n","    bins: number of bins for histogram (default None)\n","    \"\"\"\n","    f2, (ax_box2, ax_hist2) = plt.subplots(\n","        nrows=2,  # Number of rows of the subplot grid= 2\n","        sharex=True,  # x-axis will be shared among all subplots\n","        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n","        figsize=figsize,\n","    )  # creating the 2 subplots\n","    sns.boxplot(\n","        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n","    )  # boxplot will be created and a triangle will indicate the mean value of the column\n","    sns.histplot(\n","        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins\n","    ) if bins else sns.histplot(\n","        data=data, x=feature, kde=kde, ax=ax_hist2\n","    )  # For histogram\n","    ax_hist2.axvline(\n","        data[feature].mean(), color=\"green\", linestyle=\"--\"\n","    )  # Add mean to the histogram\n","    ax_hist2.axvline(\n","        data[feature].median(), color=\"black\", linestyle=\"-\"\n","    )  # Add median to the histogram\n"],"metadata":{"id":"Atzzld5ErE7i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function to create labeled barplots\n","\n","\n","def labeled_barplot(data, feature, perc=False, n=None):\n","    \"\"\"\n","    Barplot with percentage at the top\n","\n","    data: dataframe\n","    feature: dataframe column\n","    perc: whether to display percentages instead of count (default is False)\n","    n: displays the top n category levels (default is None, i.e., display all levels)\n","    \"\"\"\n","\n","    total = len(data[feature])  # length of the column\n","    count = data[feature].nunique()\n","    if n is None:\n","        plt.figure(figsize=(count + 2, 6))\n","    else:\n","        plt.figure(figsize=(n + 2, 6))\n","\n","    plt.xticks(rotation=90, fontsize=15)\n","    ax = sns.countplot(\n","        data=data,\n","        x=feature,\n","        palette=\"Paired\",\n","        order=data[feature].value_counts().index[:n],\n","    )\n","\n","    for p in ax.patches:\n","        if perc == True:\n","            label = \"{:.1f}%\".format(\n","                100 * p.get_height() / total\n","            )  # percentage of each class of the category\n","        else:\n","            label = p.get_height()  # count of each level of the category\n","\n","        x = p.get_x() + p.get_width() / 2  # width of the plot\n","        y = p.get_height()  # height of the plot\n","\n","        ax.annotate(\n","            label,\n","            (x, y),\n","            ha=\"center\",\n","            va=\"center\",\n","            size=12,\n","            xytext=(0, 5),\n","            textcoords=\"offset points\",\n","        )  # annotate the percentage\n","\n","    plt.show()  # show the plot"],"metadata":{"id":"oe8DdDj5rE5C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["histogram_boxplot(data,\"______\")"],"metadata":{"id":"FtD3YdMZrErP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labeled_barplot(data, \"_____\", perc=True, n=10)"],"metadata":{"id":"3OCsOcQKrevw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labeled_barplot(data, \"_____\", perc=True, n=10)"],"metadata":{"id":"iuU1D2EBrey5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labeled_barplot(data, \"_____\", perc=True, n=10)"],"metadata":{"id":"8oouCgU6riZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labeled_barplot(data, \"______\", perc=True, n=10)"],"metadata":{"id":"g2QvilRxriby"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["histogram_boxplot(data,\"______\")"],"metadata":{"id":"R0g27K8trieC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["histogram_boxplot(data,\"______\")"],"metadata":{"id":"0UzfKoPMrigx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["histogram_boxplot(data,\"______\")"],"metadata":{"id":"LIed7tNorijR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Bivariate Analysis\n"],"metadata":{"id":"k2TkX8iOrtzB"}},{"cell_type":"code","source":["cols_list = data.select_dtypes(include=np.number).columns.tolist()\n","# dropping views_content as it is a temporal variable\n","cols_list.remove(\"views_content\")\n","\n","plt.figure(figsize=(15, 7))\n","sns.heatmap(\n","    data[cols_list].corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\"\n",")\n","plt.show()"],"metadata":{"id":"T9MacK5kryZs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(15, 5))\n","sns.boxplot(data=data, x=\"genre\", y=\"views_content\")\n","plt.xticks(rotation=90)\n","plt.show()"],"metadata":{"id":"qcx7bM8urycp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10, 4))\n","\n","plt.subplot(121)\n","sns.boxplot(data=data, x=\"______\", y=\"_______\")\n","\n","plt.subplot(122)\n","sns.boxplot(data=data, x=\"_____\", y=_______\")\n","\n","plt.show()"],"metadata":{"id":"LWQQt11lryfp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"423MYBWC1XS3"}},{"cell_type":"markdown","source":["## Data Preprocessing\n","- Check for missing value\n","- Feature engineering (if needed)\n","- Outlier detection and treatment (if needed)\n","- Preparing data for modeling\n","- Any other preprocessing steps (if needed)"],"metadata":{"id":"ptyqSqo40l9Z"}},{"cell_type":"code","source":["df1 = data.____()# create a copy of the data"],"metadata":{"id":"cxtrdnQGrsHR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(df1.isnull().sum() / len(df1)) * 100 # Check for missing data"],"metadata":{"id":"7te0jlzTrsKJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cols_impute = [\n","    \"_________\",\n","    \"________\",\n","    \"_______\",\n","    \"_______\",\n","    \"_______\",\n","    \"_______\",\n","]\n","\n","for col in cols_impute:\n","    df1[col] = df1[col].fillna(\n","        value=df1.groupby(['_____'])[col].transform(\"median\")\n","    )   ## Complete the code to impute missing values in cols_impute with median by grouping the data on release year and brand name\n","\n","# checking for missing values\n","df1.'_______' ## Complete the code to check missing values after imputing the above columns"],"metadata":{"id":"hrUOk0KsuU8Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# outlier detection using boxplot\n","num_cols = df1.select_dtypes(include=np.number).columns.tolist()\n","\n","plt.figure(figsize=(15, 15))\n","\n","for i, variable in enumerate(num_cols):\n","    plt.subplot(4, 3, i + 1)\n","    sns.boxplot(data=df1, x=variable)\n","    plt.tight_layout(pad=2)\n","\n","plt.show()"],"metadata":{"id":"fcJ-0YC_rsMr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Complete the code to define the dependent and independent variables\n","X = df1.drop([\"visitors\"], axis=1)\n","y = df1[\"visitors\"]\n","\n","print(X.head())\n","print()\n","print(y.head())"],"metadata":{"id":"jEFp8qfcrsPS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# splitting the data in 70:30 ratio for train to test data\n","\n","x_train, x_test, y_train, y_test = '_______' ## Complete the code to split the data into train and test in specified ratio"],"metadata":{"id":"lXoyZOLFwWhc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Number of rows in train data =\", x_train.shape[0])\n","print(\"Number of rows in test data =\", '________') # fill the blank to print number of rows in test set"],"metadata":{"id":"cBDUO52RwYVa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Building"],"metadata":{"id":"qH2yb1hS1kTh"}},{"cell_type":"markdown","source":["## Model Selection"],"metadata":{"id":"ulLIJd_b0mCo"}},{"cell_type":"code","source":["olsmodel1 = '_______' ## Complete the code to fit OLS model\n","print(olsmodel1.summary())"],"metadata":{"id":"YyAyJn79xzek"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Initial Performance Check"],"metadata":{"id":"aeYL3Vmj0oQ2"}},{"cell_type":"code","source":["# function to compute MAPE\n","def mape_score(targets, predictions):\n","    return np.mean(np.abs(targets - predictions) / targets) * 100\n","\n","\n","# function to compute different metrics to check performance of a regression model\n","def model_performance_regression(model, predictors, target):\n","    \"\"\"\n","    Function to compute different metrics to check regression model performance\n","\n","    model: regressor\n","    predictors: independent variables\n","    target: dependent variable\n","    \"\"\"\n","\n","    # predicting using the independent variables\n","    pred = model.predict(predictors)\n","\n","    rmse = np.sqrt(mean_squared_error(target, pred))  # to compute RMSE\n","    mae = mean_absolute_error(target, pred)  # to compute MAE\n","    mape = mape_score(target, pred)  # to compute MAPE\n","\n","    # creating a dataframe of metrics\n","    df_perf = pd.DataFrame(\n","        {\n","            \"RMSE\": rmse,\n","            \"MAE\": mae,\n","            \"MAPE\": mape,\n","        },\n","        index=[0],\n","    )\n","\n","    return df_perf"],"metadata":{"id":"d4bEB6-ZxzpN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Training Performance\\n\")# checking model performance on train set (seen 70% data)\n","olsmodel1_train_perf = model_performance_regression('__________') # Complete the code to check the performance on train data\n","olsmodel1_train_perf"],"metadata":{"id":"182tvcaFxzr0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Test Performance\\n\")# check model performance on test set (seen 30% data)\n","olsmodel1_test_perf = model_performance_regression('__________') # Complete the code to check the performance on test data\n","olsmodel1_test_perf"],"metadata":{"id":"U5WFbp5mxzuU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training the Model\n","\n","We will be checking the following Linear Regression assumptions:\n","\n","1. **No Multicollinearity**\n","\n","2. **Linearity of variables**\n","\n","3. **Independence of error terms**\n","\n","4. **Normality of error terms**\n","\n","5. **No Heteroscedasticity**##\n","\n","TEST FOR MULTICOLLINEARITY\n","\n","- We will test for multicollinearity using VIF.\n","\n","- **General Rule of thumb**:\n","    - If VIF is 1 then there is no correlation between the $k$th predictor and the remaining predictor variables.\n","    - If VIF exceeds 5 or is close to exceeding 5, we say there is moderate multicollinearity.\n","    - If VIF is 10 or exceeding 10, it shows signs of high multicollinearity."],"metadata":{"id":"-xP7PpoK0mFI"}},{"cell_type":"code","source":["from statsmodels.stats.outliers_influence import variance_inflation_factor\n","\n","# we will define a function to check VIF\n","def checking_vif(predictors):\n","    vif = pd.DataFrame()\n","    vif[\"feature\"] = predictors.columns\n","\n","    # calculating VIF for each feature\n","    vif[\"VIF\"] = [\n","        variance_inflation_factor(predictors.values, i)\n","        for i in range(len(predictors.columns))\n","    ]\n","    return vif"],"metadata":{"id":"-LP0q_jd2EnX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checking_vif('_______')  ## Complete the code to check VIF on train data"],"metadata":{"id":"eCQwj_l02EwH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Reomving Multicollinearity (if needed)"],"metadata":{"id":"jN_Q2x_52ZVA"}},{"cell_type":"code","source":["def treating_multicollinearity(predictors, target, high_vif_columns):\n","    \"\"\"\n","    Checking the effect of dropping the columns showing high multicollinearity\n","    on model performance (adj. R-squared and RMSE)\n","\n","    predictors: independent variables\n","    target: dependent variable\n","    high_vif_columns: columns having high VIF\n","    \"\"\"\n","    # empty lists to store adj. R-squared and RMSE values\n","    adj_r2 = []\n","    rmse = []\n","\n","    # build ols models by dropping one of the high VIF columns at a time\n","    # store the adjusted R-squared and RMSE in the lists defined previously\n","    for cols in high_vif_columns:\n","        # defining the new train set\n","        train = predictors.loc[:, ~predictors.columns.str.startswith(cols)]\n","\n","        # create the model\n","        olsmodel = sm.OLS(target, train).fit()\n","\n","        # adding adj. R-squared and RMSE to the lists\n","        adj_r2.append(olsmodel.rsquared_adj)\n","        rmse.append(np.sqrt(olsmodel.mse_resid))\n","\n","    # creating a dataframe for the results\n","    temp = pd.DataFrame(\n","        {\n","            \"col\": high_vif_columns,\n","            \"Adj. R-squared after_dropping col\": adj_r2,\n","            \"RMSE after dropping col\": rmse,\n","        }\n","    ).sort_values(by=\"Adj. R-squared after_dropping col\", ascending=False)\n","    temp.reset_index(drop=True, inplace=True)\n","\n","    return temp"],"metadata":{"id":"6sbMrsQQ2E0A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["col_list = [] ## Complete the code to specify the columns with high VIF\n","\n","res = treating_multicollinearity('_____', y_train, col_list) ## Complete the code to check the effect on model performance after dropping specified columns from train data\n","res"],"metadata":{"id":"lvThcGS62nvi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["col_to_drop = '_____' ## Complete the code to specify the column to drop\n","x_train2 = '_____'.loc[:, ~'_____'.columns.str.startswith(col_to_drop)] ## Complete the code to specify the train data from which to drop the column specified\n","x_test2 = '_____'.loc[:, ~'_____'.columns.str.startswith(col_to_drop)] ## Complete the code to specify the test data from which to drop the column specified\n","\n","# Check VIF now\n","vif = checking_vif(x_train2)\n","print(\"VIF after dropping \", col_to_drop)\n","vif"],"metadata":{"id":"YEa45Mhx2n9e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dropping high p-value variable\n","- We will drop the predictor variables having a p-value greater than 0.05 as they do not significantly impact the target variable.\n","- But sometimes p-values change after dropping a variable. So, we'll not drop all variables at once.\n","- Instead, we will do the following:\n","    - Build a model, check the p-values of the variables, and drop the column with the highest p-value.\n","    - Create a new model without the dropped feature, check the p-values of the variables, and drop the column with the highest p-value.\n","    - Repeat the above two steps till there are no columns with p-value > 0.05.\n","\n","The above process can also be done manually by picking one variable at a time that has a high p-value, dropping it, and building a model again. But that might be a little tedious and using a loop will be more efficient."],"metadata":{"id":"4beRIf2D3A2X"}},{"cell_type":"code","source":["# initial list of columns\n","predictors = '_____'.copy()  ## Complete the code to check for p-values on the right dataset\n","cols = predictors.columns.tolist()\n","\n","# setting an initial max p-value\n","max_p_value = 1\n","\n","while len(cols) > 0:\n","    # defining the train set\n","    x_train_aux = predictors[cols]\n","\n","    # fitting the model\n","    model = sm.OLS(y_train, x_train_aux).fit()\n","\n","    # getting the p-values and the maximum p-value\n","    p_values = model.pvalues\n","    max_p_value = max(p_values)\n","\n","    # name of the variable with maximum p-value\n","    feature_with_p_max = p_values.idxmax()\n","\n","    if max_p_value > 0.05:\n","        cols.remove(feature_with_p_max)\n","    else:\n","        break\n","\n","selected_features = cols\n","print(selected_features)"],"metadata":{"id":"Iv3bJfAT3BJG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train2 = x_train[selected_features]\n","x_test2 = x_test[selected_features]"],"metadata":{"id":"kb1QuRpL3BL9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["olsmodel2 = '________' # Complete the code fit OLS model\n","print(olsmodel2.summary())"],"metadata":{"id":"nRKwNxY13BTe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# checking model performance on train set (seen 70% data)\n","print(\"Training Performance\\n\")\n","olsmodel2_train_perf = model_performance_regression(olsmodel2, x_train2, y_train)\n","olsmodel2_train_perf"],"metadata":{"id":"9_TamgVAnz38"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# checking model performance on test set (seen 30% data)\n","print(\"Test Performance\\n\")\n","olsmodel2_test_perf = model_performance_regression('_______') # Fill the blank to get model performance on test set\n","olsmodel2_test_perf"],"metadata":{"id":"bDD65uTBnz60"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Test for Linearity and Independence\n","\n","- We will test for linearity and independence by making a plot of fitted values vs residuals and checking for patterns.\n","- If there is no pattern, then we say the model is linear and residuals are independent.\n","- Otherwise, the model is showing signs of non-linearity and residuals are not independent."],"metadata":{"id":"rmz4DnlSn_UE"}},{"cell_type":"code","source":["# let us create a dataframe with actual, fitted and residual values\n","df_pred = pd.DataFrame()\n","\n","df_pred[\"Actual Values\"] = '_______' ## Complete the code to store the actual values\n","df_pred[\"Fitted Values\"] = olsmodel2.fittedvalues  # predicted values\n","df_pred[\"Residuals\"] = olsmodel2..resid  # residuals\n","\n","df_pred.head()"],"metadata":{"id":"SvPhA_Ugn2hx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# let's plot the fitted values vs residuals\n","\n","sns.residplot(\n","    data=df_pred, x=\"Fitted Values\", y=\"Residuals\", color=\"purple\", lowess=True\n",")\n","plt.xlabel(\"Fitted Values\")\n","plt.ylabel(\"Residuals\")\n","plt.title(\"Fitted vs Residual plot\")\n","plt.show()"],"metadata":{"id":"RtOeo0Khn2kd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["TEST FOR HOMOSCEDASTICITY\n","- We will test for normality by checking the distribution of residuals, by checking the Q-Q plot of residuals, and by using the Shapiro-Wilk test.\n","- If the residuals follow a normal distribution, they will make a straight line plot, otherwise not.\n","- If the p-value of the Shapiro-Wilk test is greater than 0.05, we can say the residuals are normally distributed."],"metadata":{"id":"6nVGTqJCoSGp"}},{"cell_type":"code","source":["import statsmodels.stats.api as sms\n","from statsmodels.compat import lzip\n","\n","name = [\"F statistic\", \"p-value\"]\n","test = '_______' ## Complete the code to check homoscedasticity\n","lzip(name, test)"],"metadata":{"id":"agbsupl3n2nL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Final Model Summary"],"metadata":{"id":"oQ5FXHGTomzf"}},{"cell_type":"code","source":["olsmodel_final = '_______' # fill the blank to fit the final model\n","print(olsmodel_final.summary())"],"metadata":{"id":"RgSp27SEoykQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# checking model performance on train set (seen 70% data)\n","print(\"Training Performance\\n\")\n","olsmodel_final_train_perf = model_performance_regression('______') # fill the blank to check the performance on train data\n","olsmodel_final_train_perf"],"metadata":{"id":"NK1372HCoym7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# checking model performance on test set (seen 30% data)\n","print(\"Test Performance\\n\")\n","olsmodel_final_test_perf = model_performance_regression('______') # fill the blank to check the performance on train data\n","olsmodel_final_test_perf"],"metadata":{"id":"fRL9qa03o16T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### LATER Enhancments\n"],"metadata":{"id":"F1nwabpaoiav"}},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"xu56BUYQ0mIA"}},{"cell_type":"markdown","source":["## Tuning and Optimizaiton"],"metadata":{"id":"h62nGRXb0mKs"}},{"cell_type":"markdown","source":["## User Interface (Optional)"],"metadata":{"id":"xSl9x1Z80mNh"}},{"cell_type":"markdown","source":["## Integration (Optional)"],"metadata":{"id":"JhnCAxso0mQI"}},{"cell_type":"markdown","source":["## Testing"],"metadata":{"id":"FZ6vo-eB0mTB"}},{"cell_type":"markdown","source":["## Feedback Loop"],"metadata":{"id":"CiJWPSe51V-G"}},{"cell_type":"markdown","source":["## Deployment"],"metadata":{"id":"505Y9BW91V5m"}},{"cell_type":"markdown","source":["## Scaling (Extention)"],"metadata":{"id":"p8fJ3j7d1e4N"}}]}